{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb752cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chigozie\\miniconda3\\envs\\zindi\\Lib\\site-packages\\codecarbon\\core\\gpu.py:4: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "[codecarbon WARNING @ 20:58:00] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 20:58:00] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 20:58:00] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 20:58:04] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 20:58:04] CPU Model on constant consumption mode: Intel(R) Core(TM) i7-4600U CPU @ 2.10GHz\n",
      "[codecarbon WARNING @ 20:58:04] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 20:58:04] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 20:58:04] No GPU found.\n",
      "[codecarbon INFO @ 20:58:04] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: global constant\n",
      "                GPU Tracking Method: Unspecified\n",
      "            \n",
      "[codecarbon INFO @ 20:58:04] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 20:58:04]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 20:58:04]   Python version: 3.13.5\n",
      "[codecarbon INFO @ 20:58:04]   CodeCarbon version: 3.0.5\n",
      "[codecarbon INFO @ 20:58:04]   Available RAM : 7.900 GB\n",
      "[codecarbon INFO @ 20:58:04]   CPU count: 4 thread(s) in 4 physical CPU(s)\n",
      "[codecarbon INFO @ 20:58:04]   CPU model: Intel(R) Core(TM) i7-4600U CPU @ 2.10GHz\n",
      "[codecarbon INFO @ 20:58:04]   GPU count: None\n",
      "[codecarbon INFO @ 20:58:04]   GPU model: None\n",
      "[codecarbon INFO @ 20:58:04] Emissions data (if any) will be saved to file c:\\Users\\Chigozie\\competitions\\zindi\\MPEG_Microbiome\\data_main\\mpeg_submission\\pos13_mpeg_final_submission\\emissions.csv\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from codecarbon import EmissionsTracker\n",
    "tracker = EmissionsTracker(project_name=\"central_model_emissions1\")\n",
    "tracker.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4661e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 20:58:19] Energy consumed for RAM : 0.000042 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 20:58:19] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 20:58:19] Energy consumed for All CPU : 0.000125 kWh\n",
      "[codecarbon INFO @ 20:58:19] 0.000167 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import os, re, gc\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from typing import Literal, Optional, Union\n",
    "import copy, logging, warnings\n",
    "import joblib\n",
    "from functools import partial\n",
    "from modelling_utils import KmerAutoEncoder, KmerClassifier, AutoEncoderScaler, normalise_counts, load_encoder_model\n",
    "from fl_utils import create_dataloader, get_embeddings, train_loop, test_loop, print_info\n",
    "import visual_utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cdb87af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2d1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc31575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (files in kmer x sampleIDs)\n",
    "train = pd.read_parquet('../data/train_8kmer.parquet')\n",
    "test = pd.read_parquet('../data/test_8kmer.parquet')\n",
    "train_labels = pd.read_csv('../data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4665ccb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2901, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train_labels.assign(ID = train_labels.filename.str.replace('.mgb', '').str.strip())\n",
    "\n",
    "# rename and select ID and target\n",
    "train_labels = train_labels.rename(columns={'SampleType': 'target'})[['ID', 'target']]\n",
    "\n",
    "# set train labels to match with train columns arrangement\n",
    "train_labels = train_labels.set_index('ID').reindex(train.columns)\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71289d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = dict(zip(\n",
    "    np.sort(train_labels['target'].unique()), \n",
    "    range(train_labels['target'].nunique())\n",
    "))\n",
    "\n",
    "train_labels['class_int'] = train_labels['target'].map(class_map)\n",
    "\n",
    "target = train_labels.class_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424431e",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Normalising kmer counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "913643fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising kmer counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 20:58:34] Energy consumed for RAM : 0.000083 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 20:58:34] Delta energy consumed for CPU with constant : 0.000126 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 20:58:34] Energy consumed for All CPU : 0.000251 kWh\n",
      "[codecarbon INFO @ 20:58:34] 0.000334 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:58:49] Energy consumed for RAM : 0.000125 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 20:58:49] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 20:58:49] Energy consumed for All CPU : 0.000376 kWh\n",
      "[codecarbon INFO @ 20:58:49] 0.000501 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2901, 65536), (1068, 65536))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Normalising kmer counts')\n",
    "train_norm = normalise_counts(train.T)\n",
    "test_norm = normalise_counts(test.T)\n",
    "\n",
    "train_norm.shape, test_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d130c8",
   "metadata": {},
   "source": [
    "### Extracting Autoencoders\n",
    "\n",
    "We will extract autoencoder embeddings from saved autoencoder. The trained autoencoder was developed such that the input data were standardised using standardscaler. Hence, we will first scale and extract their embeddings. After that, we will load our saved autoencoder model. This saved model depends on the loaded `KmerAutoEncoder` class. We will use the load_encoder_model function to do that by passing the file path. \n",
    "\n",
    "This was done as a dimensionality reduction strategy for fast compute and modelling as against the 66k kmers from ($4^8$ possible 8-kmer sequences). The about 66k kmer features were reduced to 64 embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44cf6ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 20:59:04] Energy consumed for RAM : 0.000166 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 20:59:04] Delta energy consumed for CPU with constant : 0.000124 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 20:59:04] Energy consumed for All CPU : 0.000500 kWh\n",
      "[codecarbon INFO @ 20:59:04] 0.000666 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AutoEncoderScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>AutoEncoderScaler</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>AutoEncoderScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "AutoEncoderScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_scaler = AutoEncoderScaler(scale=True, scale_type='ss')\n",
    "encoder_scaler.fit(train_norm)\n",
    "\n",
    "# joblib.dump(encoder_scaler, 'data/models/encoder_scaler.pkl') # saving for use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9703fd",
   "metadata": {},
   "source": [
    "__Scale and transform autoencoders__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling and transforming train and test data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Scaling and transforming train and test data\\n')\n",
    "scaled_train_norm = encoder_scaler.transform(train_norm)\n",
    "scaled_test_norm = encoder_scaler.transform(test_norm)\n",
    "\n",
    "# load autoencoder model\n",
    "encoder_path = glob('../data/models/*latent64*.pth')[0]\n",
    "encoder_path\n",
    "\n",
    "encoder_model = load_encoder_model(encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "758663a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for train and test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 20:59:19] Energy consumed for RAM : 0.000208 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 20:59:19] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 20:59:19] Energy consumed for All CPU : 0.000626 kWh\n",
      "[codecarbon INFO @ 20:59:19] 0.000833 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 20:59:34] Energy consumed for RAM : 0.000249 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 20:59:34] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 20:59:34] Energy consumed for All CPU : 0.000751 kWh\n",
      "[codecarbon INFO @ 20:59:34] 0.001000 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "# extract embeddings\n",
    "print('Extracting embeddings for train and test data')\n",
    "train_embeddings = get_embeddings(encoder_model, scaled_train_norm)\n",
    "test_embeddings = get_embeddings(encoder_model, scaled_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d935d1e",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196b3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KmerPipeline:\n",
    "    def __init__(self, model_fn, criterion, optimiser_fn, preprocessor):\n",
    "        super().__init__()\n",
    "        self.model_fn = model_fn # callable\n",
    "        self.optimiser_fn = optimiser_fn # callable\n",
    "        self.model = None\n",
    "        self.preprocessor = preprocessor\n",
    "        self.criterion = criterion\n",
    "        self.optimiser = None\n",
    "        self.best_model_state = None\n",
    "    \n",
    "    def train_model(self, X, y, Xval=None, yval=None, epochs=50, batch_size=32, \n",
    "                    shuffle=True, early_stopping_rounds=None, print_rounds=5, \n",
    "                    seed=None, verbose=False):\n",
    "        set_seed(seed)\n",
    "        y = np.array(y)\n",
    "        # preprocessor\n",
    "        self.preprocessor.fit(X, y)\n",
    "        X = self.preprocessor.transform(X) \n",
    "\n",
    "        # build model\n",
    "        input_dim = X.shape[1]\n",
    "        num_classes = len(np.unique(y))\n",
    "        self.model = self.model_fn(input_dim, num_classes).to(device)\n",
    "        self.optimiser = self.optimiser_fn(self.model)\n",
    "        \n",
    "        # convert to tensor and dataloader\n",
    "        train_loader = create_dataloader(X, y, batch_size=128, shuffle=shuffle)\n",
    "        \n",
    "        if Xval is not None and yval is not None:\n",
    "            yval = np.array(yval)\n",
    "            Xval = self.preprocessor.transform(Xval)\n",
    "            val_loader = create_dataloader(Xval, yval, batch_size=64, shuffle=True)\n",
    "        else:\n",
    "            val_loader = None\n",
    "        # fit model\n",
    "        best_loss = float('inf'); wait = 0; best_epoch = None; best_model_train_loss = float('inf')\n",
    "        for epoch in range(1, epochs+1):\n",
    "            train_loss = train_loop(self.model, self.criterion, self.optimiser, train_loader)\n",
    "            if val_loader is not None:\n",
    "                val_loss = test_loop(self.model, self.criterion, val_loader)['loss']\n",
    "                if verbose:\n",
    "                    if print_info(epoch, epochs, print_rounds):\n",
    "                        print(f\"Epoch {epoch}: Train Loss: {train_loss:.7f}, Val Loss: {val_loss:.7f}\")\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_epoch = epoch\n",
    "                    best_model_train_loss = train_loss\n",
    "                    self.best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                    wait = 0\n",
    "                else:\n",
    "                    wait += 1\n",
    "            else:\n",
    "                if verbose:\n",
    "                    if print_info(epoch, epochs, print_rounds):\n",
    "                        print(f\"Epoch {epoch}: Train Loss: {train_loss:.7f}\")\n",
    "                if train_loss < best_loss:\n",
    "                    best_loss = train_loss\n",
    "                    best_epoch = epoch\n",
    "                    self.best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                    wait = 0\n",
    "                else:\n",
    "                    wait += 1\n",
    "            # early stopping\n",
    "            if early_stopping_rounds and wait >= early_stopping_rounds:\n",
    "                # print(f\"\\nEarly stopping triggered at epoch {epoch}. No improvement after {early_stopping_rounds} epochs.\")\n",
    "                break\n",
    "        # print best model\n",
    "        if val_loader is not None:\n",
    "            print(f'Best Model: Epoch: {best_epoch}, Train Loss: {best_model_train_loss:.7f}, Val Loss: {best_loss:.7f}')\n",
    "        else:\n",
    "            print(f'Best Model: Epoch: {best_epoch}, Train Loss: {best_loss:.7f}')\n",
    "        if self.best_model_state:\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        X = self.preprocessor.transform(X)\n",
    "        test_loader = create_dataloader(X, batch_size=64, shuffle=False)\n",
    "        probabilities = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in test_loader:\n",
    "                outputs = self.model(inputs.to(device))\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                probabilities.append(probs.cpu().numpy())\n",
    "        return np.vstack(probabilities)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9de232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(probs, ids, filename):\n",
    "    cols = list(class_map.keys())\n",
    "    path = './'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    df = pd.DataFrame()\n",
    "    df['ID'] = ids\n",
    "    df[cols] = probs\n",
    "    print(df)\n",
    "    filepath = os.path.join(path, f'{filename}.csv')\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55352ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = StandardScaler() # preprocessor\n",
    "rms_optimiser = lambda model, lr=0.0005: torch.optim.RMSprop(model.parameters(), lr=lr) # optimiser\n",
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "\n",
    "# instantiate model\n",
    "model = partial(KmerClassifier, layer_mult=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e8917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_embeddings\n",
    "y = train_labels.class_int.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce378e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling\n",
      "===============\n",
      "Training started..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 20:59:49] Energy consumed for RAM : 0.000291 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 20:59:49] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 20:59:49] Energy consumed for All CPU : 0.000875 kWh\n",
      "[codecarbon INFO @ 20:59:49] 0.001166 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.3520152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:00:04] Energy consumed for RAM : 0.000332 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 21:00:04] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 21:00:04] Energy consumed for All CPU : 0.001001 kWh\n",
      "[codecarbon INFO @ 21:00:04] 0.001333 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:00:04] 0.004619 g.CO2eq/s mean an estimation of 145.66201113854103 kg.CO2eq/year\n",
      "[codecarbon INFO @ 21:00:19] Energy consumed for RAM : 0.000374 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 21:00:19] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 21:00:19] Energy consumed for All CPU : 0.001125 kWh\n",
      "[codecarbon INFO @ 21:00:19] 0.001499 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150: Train Loss: 0.0011327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:00:34] Energy consumed for RAM : 0.000416 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 21:00:34] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 21:00:34] Energy consumed for All CPU : 0.001250 kWh\n",
      "[codecarbon INFO @ 21:00:34] 0.001666 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: Train Loss: 0.0000335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:00:49] Energy consumed for RAM : 0.000457 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 21:00:49] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 21:00:49] Energy consumed for All CPU : 0.001375 kWh\n",
      "[codecarbon INFO @ 21:00:49] 0.001833 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 21:01:04] Energy consumed for RAM : 0.000499 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 21:01:04] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 21:01:04] Energy consumed for All CPU : 0.001500 kWh\n",
      "[codecarbon INFO @ 21:01:04] 0.001999 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450: Train Loss: 0.0000834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:01:19] Energy consumed for RAM : 0.000541 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 21:01:19] Delta energy consumed for CPU with constant : 0.000125 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 21:01:19] Energy consumed for All CPU : 0.001625 kWh\n",
      "[codecarbon INFO @ 21:01:19] 0.002166 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Epoch: 441, Train Loss: 0.0000076\n",
      "Training Completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define model pipeline and train model\n",
    "print('Modelling\\n===============')\n",
    "print('Training started..')\n",
    "model_pipe = KmerPipeline(model, criterion, rms_optimiser, preprocessor)\n",
    "model_pipe.train_model(X, y, epochs=2000, early_stopping_rounds=100, \n",
    "                       print_rounds=150, batch_size=256, seed=42, verbose=True)\n",
    "\n",
    "print('Training Completed!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe461225",
   "metadata": {},
   "source": [
    "### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "028444c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = test.columns\n",
    "len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0cde57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test probabilities..\n",
      "Saving test predictions\n",
      "\n",
      "             ID         Mouth         Nasal          Skin         Stool\n",
      "0     ID_UOIPKJ  6.081013e-09  4.005314e-09  4.161660e-09  1.000000e+00\n",
      "1     ID_XHBQPF  9.999944e-01  1.627582e-06  3.748464e-06  1.815283e-07\n",
      "2     ID_KYILXT  9.999998e-01  2.386512e-07  4.160470e-08  2.857757e-08\n",
      "3     ID_UFGHMX  1.425549e-08  1.812382e-09  1.009929e-08  1.000000e+00\n",
      "4     ID_URMZQG  2.947394e-07  9.999998e-01  1.123976e-08  1.493887e-09\n",
      "...         ...           ...           ...           ...           ...\n",
      "1063  ID_FUMEPV  7.672558e-06  9.999915e-01  6.516010e-07  2.106426e-07\n",
      "1064  ID_RWUAEX  8.611288e-08  1.936774e-06  1.670381e-08  9.999980e-01\n",
      "1065  ID_PLZYXW  9.999894e-01  1.027714e-05  2.130637e-07  7.681781e-08\n",
      "1066  ID_TJNQXM  4.870396e-08  8.864474e-09  9.999998e-01  1.886305e-07\n",
      "1067  ID_DSBIZA  5.625661e-08  2.241479e-09  3.627793e-10  1.000000e+00\n",
      "\n",
      "[1068 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:01:21] Energy consumed for RAM : 0.000546 kWh. RAM Power : 10.0 W\n",
      "[codecarbon INFO @ 21:01:21] Delta energy consumed for CPU with constant : 0.000015 kWh, power : 30.0 W\n",
      "[codecarbon INFO @ 21:01:21] Energy consumed for All CPU : 0.001640 kWh\n",
      "[codecarbon INFO @ 21:01:21] 0.002186 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0009108297831768457"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_predictions\n",
    "print('Predicting test probabilities..')\n",
    "test_probs = model_pipe.predict_proba(test_embeddings)\n",
    "\n",
    "os.makedirs('preds', exist_ok=True)\n",
    "print('Saving test predictions\\n')\n",
    "save_file(test_probs, test_idx, 'preds/centralised_LB_score1')\n",
    "\n",
    "tracker.stop() # stop carbon emission tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9377be",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2af4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing cross-validation\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerforming cross-validation\\n==============================')\n",
    "folds = np.zeros(len(train_norm))\n",
    "skfold = StratifiedKFold(shuffle=True, random_state=42)\n",
    "for i, (_, val_idx) in enumerate(skfold.split(train_norm, train_labels.class_int)):\n",
    "    folds[val_idx] = i\n",
    "\n",
    "def cross_validation(clf, optimiser, criterion, train_emb, y=target, cv_folds:int=5, verbose=False):\n",
    "    lloss = []\n",
    "    \n",
    "    skfold = StratifiedKFold(cv_folds, shuffle=True, random_state=42)\n",
    "    for i in range(len(np.unique(folds))):\n",
    "        val_idx = folds == i\n",
    "        xtrain, ytrain = train_emb[~val_idx], y.loc[~val_idx]\n",
    "        xval, yval = train_emb[val_idx], y.loc[val_idx]\n",
    "        \n",
    "        model_pipe = KmerPipeline(model, criterion, rms_optimiser, preprocessor)\n",
    "        model_pipe.train_model(xtrain, ytrain, xval, yval, epochs=2000, early_stopping_rounds=100, \n",
    "                               print_rounds=500, batch_size=256, seed=42, verbose=False)\n",
    "        \n",
    "        # evaluate\n",
    "        res = visual_utils.classification_eval_metrics(model_pipe, xval, yval)\n",
    "        if verbose:\n",
    "            print(f'\\nFold {i+1}\\tLogLoss: {np.array(res.LLoss).squeeze()}')\n",
    "            print('=='*30)\n",
    "        lloss.append(np.array(res.LLoss).squeeze())\n",
    "    avg_lloss = np.mean(lloss)\n",
    "    ci95_l, ci95_h = np.quantile(lloss, [0.025, 0.975])\n",
    "    print(f'\\nAvg LLoss: {avg_lloss:.8f}')\n",
    "    print(f'95th CI: [{ci95_l:.8f}, {ci95_h:.8f}]\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3a407dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Epoch: 142, Train Loss: 0.0012119, Val Loss: 0.0054802\n",
      "\n",
      "Fold 1\tLogLoss: 0.005919387427609668\n",
      "============================================================\n",
      "Best Model: Epoch: 151, Train Loss: 0.0029829, Val Loss: 0.0088834\n",
      "\n",
      "Fold 2\tLogLoss: 0.009789484053319778\n",
      "============================================================\n",
      "Best Model: Epoch: 79, Train Loss: 0.0035035, Val Loss: 0.0056103\n",
      "\n",
      "Fold 3\tLogLoss: 0.006163785992986322\n",
      "============================================================\n",
      "Best Model: Epoch: 82, Train Loss: 0.0023723, Val Loss: 0.0064833\n",
      "\n",
      "Fold 4\tLogLoss: 0.007132724746008334\n",
      "============================================================\n",
      "Best Model: Epoch: 25, Train Loss: 0.0093308, Val Loss: 0.0195971\n",
      "\n",
      "Fold 5\tLogLoss: 0.021105233866455096\n",
      "============================================================\n",
      "\n",
      "Avg LLoss: 0.01002212\n",
      "95th CI: [0.00594383, 0.01997366]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validation(KmerClassifier, rms_optimiser, criterion, train_embeddings, target, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aa42949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken : 6.8935 Mins\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "mins = (end - start)/60\n",
    "print(f'Total Time taken : {mins:.4f} Mins')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
